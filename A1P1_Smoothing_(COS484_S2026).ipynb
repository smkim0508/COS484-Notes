{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smkim0508/COS484-Notes/blob/main/A1P1_Smoothing_(COS484_S2026).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX7_-K31Zp7y"
      },
      "source": [
        "# Notebook for Programming Question 1\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a theory portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing).\n",
        "\n",
        "We'll also be programming in Python, which we will assume a basic familiarity with. Python has fantastic community support and we'll be using numerous packages for machine learning (ML) and natural language processing (NLP) tasks.\n",
        "\n",
        "### Learning Objectives\n",
        "In this problem we will experiment with language models and implement smoothing. We will also see effects of using unigram/bigram LMs and the size of the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPv_JEf8ZvIb"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "In this section, you should write methods to load data and clean (tokenize) it. You will need to write two functions for tokenization. One function, **basicTokenize**, should simply split the text using whitespace. The other function, **nltkTokenize**, should implement NLTK tokenization. Write another function to count the top k most frequent words in a list. You may structure this code however you like, but we suggest constructing a Tokenizer class to encompass these functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2apYXiYZxog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4ea65a-699f-44bf-b638-7fd780f9a3fe"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "class Tokenizer():\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def basicTokenize(self, text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    splits text by whitespace\n",
        "    \"\"\"\n",
        "    return text.split()\n",
        "\n",
        "  def nltkTokenize(self, text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    splits token using nltk library\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "  def count_top_words(self, words: list[str], k: int) -> list[tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    counts the top k words and returns the top k as a sorted list\n",
        "    \"\"\"\n",
        "    word_counts = {}\n",
        "    for word in words:\n",
        "      if word in word_counts:\n",
        "        word_counts[word] += 1\n",
        "      else:\n",
        "        word_counts[word] = 1\n",
        "\n",
        "    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_word_counts[:k]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "# test tokenization\n",
        "text = \"This is a test string. I like food.\"\n",
        "basic_tokens = tokenizer.basicTokenize(text)\n",
        "nltk_tokens = tokenizer.nltkTokenize(text)\n",
        "\n",
        "print(f\"Basic Tokenization: {basic_tokens}\")\n",
        "print(f\"NLTK Tokenization: {nltk_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqTCFJSqzmzd",
        "outputId": "692ee5bd-0e6f-4617-d94d-96033655bfd7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic Tokenization: ['This', 'is', 'a', 'test', 'string.', 'I', 'like', 'food.']\n",
            "NLTK Tokenization: ['This', 'is', 'a', 'test', 'string', '.', 'I', 'like', 'food', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = tokenizer.count_top_words(nltk_tokens, 3)\n",
        "top_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slwj6mRe0RUW",
        "outputId": "9ad543df-9fbc-42e9-f469-24a29fa3f58f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 2), ('This', 1), ('is', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXYBlcTyagBQ"
      },
      "source": [
        "### Language Modeling and Smoothing\n",
        "In this section, you should write methods to train and test a bigram language model. These functions will need to include computing bigram counts, estimating bigram probabilities, and calculating perplexity on the test set. You should also implement a method that can later be called to modify the probabilities with add-alpha smoothing. We suggest encompassing these functions in a LanguageModel class to make experiments easier to run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "class LanguageModel():\n",
        "\n",
        "  def __init__(self, word_to_index: dict, index_to_word: list):\n",
        "    self.word_to_index = word_to_index\n",
        "    self.index_to_word = index_to_word\n",
        "    self.vocab_size = len(word_to_index)\n",
        "    # init VxV matrix for cooccurrence (bigram count), initialized to zeros\n",
        "    self.bigram_counts = [[0] * self.vocab_size for _ in range(self.vocab_size)]\n",
        "    # init VxV matrix for bigram probabilities\n",
        "    self.bigram_probs = [[0.0] * self.vocab_size for _ in range(self.vocab_size)]\n",
        "\n",
        "  def compute_bigram_counts(self, tokens: list[str]):\n",
        "    \"\"\"\n",
        "    Computes bigram counts from a list of tokens.\n",
        "    \"\"\"\n",
        "    for i in tqdm(range(len(tokens) - 1), desc=\"bigram counts\"):\n",
        "      word1 = tokens[i]\n",
        "      word2 = tokens[i+1]\n",
        "\n",
        "      if word1 in self.word_to_index and word2 in self.word_to_index:\n",
        "        idx1 = self.word_to_index[word1]\n",
        "        idx2 = self.word_to_index[word2]\n",
        "        self.bigram_counts[idx1][idx2] += 1\n",
        "\n",
        "  def compute_bigram_probs(self, alpha = 0.0):\n",
        "    \"\"\"\n",
        "    Compute a bigram probability matrix using bigram counts.\n",
        "    \"\"\"\n",
        "\n",
        "    for i in tqdm(range(self.vocab_size), desc=\"bigram probability\"):\n",
        "      row_sum = sum(self.bigram_counts[i])\n",
        "      for j in range(self.vocab_size):\n",
        "        # prob for an element is the count / total number of counts in this row\n",
        "        # NOTE: adds alpha to smooth\n",
        "        d = (row_sum + (alpha * self.vocab_size))\n",
        "        if d == 0:\n",
        "          print(f\"row sum is 0, please adjust alpha value to prevent division by 0\")\n",
        "          break # skips the rest of this row, leaves the prob as 0.0\n",
        "        self.bigram_probs[i][j] = (self.bigram_counts[i][j] + alpha) / d\n",
        "\n",
        "  def perplexity(self, tokens: list[str]) -> float:\n",
        "    \"\"\"\n",
        "    Computes perplexity of a tokenized sentence.\n",
        "    tokens should include <s> and </s>\n",
        "    Uses the pre-computed bigram probabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    log_sum = 0.0\n",
        "    N = 0\n",
        "\n",
        "    for i in tqdm(range(len(tokens) - 1), desc=\"perplexity\"):\n",
        "      prev_word = tokens[i]\n",
        "      curr_word = tokens[i+1]\n",
        "\n",
        "      i1 = self.word_to_index[prev_word]\n",
        "      i2 = self.word_to_index[curr_word]\n",
        "\n",
        "      prob = self.bigram_probs[i1][i2]\n",
        "\n",
        "      # if any prob = 0, log -> -inf, so perplexity -> +inf\n",
        "      if not prob:\n",
        "        return float('inf')\n",
        "\n",
        "      log_sum += math.log(prob)\n",
        "      N += 1\n",
        "\n",
        "    return math.exp(-log_sum / N)"
      ],
      "metadata": {
        "id": "TqY5-AJMDqs5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkIAhWqYeUgL"
      },
      "source": [
        "### Instantiate an LM and calculate perplexity\n",
        "Write a wrapper method to train and evaluate a language model on a given train and dev corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nILv3Tyleb54"
      },
      "source": [
        "# training in this case -> calculating counts and probabilities; testing -> checking perplexity on test sentence.\n",
        "def train_lm(language_model: LanguageModel, train_tokens: list[str]):\n",
        "  \"\"\"\n",
        "  Takes an instance of LM model class and trains it.\n",
        "  Uses training tokens given from train corpus.\n",
        "  \"\"\"\n",
        "  language_model.compute_bigram_counts(train_tokens)\n",
        "  language_model.compute_bigram_probs(alpha = 1.0)\n",
        "  return language_model\n",
        "\n",
        "def evaluate_lm(language_model: LanguageModel, test_tokens: list[str]) -> float:\n",
        "  \"\"\"\n",
        "  Takes an instance of LM model class and evaluates it using perplexity.\n",
        "  Uses test tokens given from training/validation corpus.\n",
        "  \"\"\"\n",
        "  return language_model.perplexity(test_tokens)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hSR_9VczRI"
      },
      "source": [
        "### Load and tokenize the training and validation data using your code from the Data Processing section\n",
        "\n",
        "You can download training and validation datasets for this problem from the links below:\n",
        "*   Training data: https://princeton-nlp.github.io/cos484/assignments/a1/brown-train.txt\n",
        "*   Validation data: https://princeton-nlp.github.io/cos484/assignments/a1/brown-val.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUH84NUc1rL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074e1ae2-a162-442c-8009-b03cfa7414db"
      },
      "source": [
        "import os\n",
        "\n",
        "# download data into data/... dir\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# training\n",
        "!wget -P data/ https://princeton-nlp.github.io/cos484/assignments/a1/brown-train.txt\n",
        "# validation\n",
        "!wget -P data/ https://princeton-nlp.github.io/cos484/assignments/a1/brown-val.txt\n",
        "\n",
        "# training path, load data into train_text\n",
        "file_path = 'data/brown-train.txt'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    train_text = file.read()\n",
        "\n",
        "# tokenize w/ nltk tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "train_tokens = tokenizer.nltkTokenize(train_text)\n",
        "# define vocab as unique set of words in training corpus\n",
        "# NOTE: should it be unique set of words in training AND validation corpus?\n",
        "vocabulary = sorted(list(set(train_tokens)))\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "# map word to index for initializing LM\n",
        "word_to_index = {word: i for i, word in enumerate(vocabulary)}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-15 17:32:05--  https://princeton-nlp.github.io/cos484/assignments/a1/brown-train.txt\n",
            "Resolving princeton-nlp.github.io (princeton-nlp.github.io)... 185.199.111.153, 185.199.108.153, 185.199.109.153, ...\n",
            "Connecting to princeton-nlp.github.io (princeton-nlp.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3524251 (3.4M) [text/plain]\n",
            "Saving to: ‘data/brown-train.txt.6’\n",
            "\n",
            "brown-train.txt.6   100%[===================>]   3.36M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2026-02-15 17:32:05 (44.3 MB/s) - ‘data/brown-train.txt.6’ saved [3524251/3524251]\n",
            "\n",
            "--2026-02-15 17:32:05--  https://princeton-nlp.github.io/cos484/assignments/a1/brown-val.txt\n",
            "Resolving princeton-nlp.github.io (princeton-nlp.github.io)... 185.199.111.153, 185.199.108.153, 185.199.109.153, ...\n",
            "Connecting to princeton-nlp.github.io (princeton-nlp.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 888444 (868K) [text/plain]\n",
            "Saving to: ‘data/brown-val.txt.6’\n",
            "\n",
            "brown-val.txt.6     100%[===================>] 867.62K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2026-02-15 17:32:05 (16.6 MB/s) - ‘data/brown-val.txt.6’ saved [888444/888444]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtrPOKd1vvyx"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anwiyViHMCTt"
      },
      "source": [
        "#### Plot the frequency of words\n",
        "Code for sub-part (a)(b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1xEdVHxMl0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "8fb01712-f7c2-404b-8cfb-c81c7309d0dd"
      },
      "source": [
        "# a) tokenize and count top words from training corpus\n",
        "nltk_train_tokens = tokenizer.nltkTokenize(train_text)\n",
        "basic_train_tokens = tokenizer.basicTokenize(train_text)\n",
        "\n",
        "top_ten_nltk = tokenizer.count_top_words(nltk_train_tokens, 10)\n",
        "top_ten_basic = tokenizer.count_top_words(basic_train_tokens, 10)\n",
        "\n",
        "print(f\"top 10 words in basic tokenization: {top_ten_basic}\")\n",
        "print(f\"top 10 words in nltk tokenization: {top_ten_nltk}\")\n",
        "\n",
        "# b) count top 100 words from nltk tokenization, then plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_hundred_nltk = tokenizer.count_top_words(nltk_train_tokens, 100)\n",
        "\n",
        "# parse x, y values to plot\n",
        "ranks = [i for i in range(1, 101)]\n",
        "frequencies = [freq for word, freq in top_hundred_nltk]\n",
        "\n",
        "plt.plot(ranks, frequencies)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 10 words in basic tokenization: [('UNK', 61019), ('the', 40854), ('of', 25087), ('and', 17563), ('to', 16190), ('a', 13659), ('in', 12973), ('is', 7378), ('that', 6324), ('for', 6000)]\n",
            "top 10 words in nltk tokenization: [('UNK', 61019), ('the', 41029), ('of', 25132), (',', 23570), ('.', 17873), ('and', 17814), ('to', 16269), ('a', 13777), ('in', 13071), ('is', 7608)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(a) **Report the top 10 words ordered by their frequency in the training corpus, both using basicTokenize and nltkTokenize. What differences do you notice between the two?**\n",
        "\n",
        "top 10 words in basic tokenization: [('UNK', 61019), ('the', 40854), ('of', 25087), ('and', 17563), ('to', 16190), ('a', 13659), ('in', 12973), ('is', 7378), ('that', 6324), ('for', 6000)]\n",
        "top 10 words in nltk tokenization: [('UNK', 61019), ('the', 41029), ('of', 25132), (',', 23570), ('.', 17873), ('and', 17814), ('to', 16269), ('a', 13777), ('in', 13071), ('is', 7608)]\n",
        "\n",
        "While the two tokenization method's resulting top 10 word frequencies look similar at first, below are some differences I noticed:\n",
        "- articles, prepositions, conjunctions like 'the', 'a', 'of', 'to', 'and', etc. appear more frequently in NLTK version.\n",
        "- punctuation marks like ',' or '.' appear far more frequently in the NLTK tokenization, this is likely because basic word tokenization using word split counts punctuation marks as part of the appended word, so their count is not found in isolation (very sparsely distributed among the appended words).\n",
        "\n",
        "**(b) Using the nltkTokenize function you wrote, make a plot of the frequencies of words in the training corpus, ordered by their rank, i.e. most frequent word first, the second most word next, and so on on the x axis. Plot only the top 100 most common words to see the trend more clearly. What pattern do you observe in your plot regarding frequency and rank? Do the frequencies follow Zipf's law?**\n",
        "\n",
        "There seems to be a small set of words whose frequency is extremely high relative to other words in the corpus, as shown by the extreme high starting point leading to a very sharp drop. Moreover, the rest of the words (majority) in the corpus display very low frequency relative to this small set of extremely high-frequency words, shown by the slow slope after the initial drop. This roughly follows Zipf's law, showing a graph similar to freq ~ C/rank, with some bumps in the curve (normal for real datasets)."
      ],
      "metadata": {
        "id": "NW8i6tdW5oYi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAWeJQ8VdBHU"
      },
      "source": [
        "#### Report the train and test perplexity after learning the language model\n",
        "Code for sub-part (c)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH79REFCcNRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0aceea3-071c-4e85-9d07-dc155e209ac5"
      },
      "source": [
        "# init lm with word to index and index to word utils, then call helper train / test methods\n",
        "\n",
        "# init\n",
        "lm = LanguageModel(word_to_index, vocabulary)\n",
        "# train\n",
        "lm = train_lm(lm, train_tokens)\n",
        "\n",
        "# load in val text and create validation tokens\n",
        "file_path = 'data/brown-val.txt'\n",
        "with open(file_path, 'r'):\n",
        "  val_text = file.read()\n",
        "valid_tokens = tokenizer.nltkTokenize(val_text)\n",
        "\n",
        "# test\n",
        "train_pp = evaluate_lm(lm, train_tokens)\n",
        "valid_pp = evaluate_lm(lm, valid_tokens)\n",
        "\n",
        "print(\"Train perplexity:\", train_pp)\n",
        "print(\"Valid perplexity:\", valid_pp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bigram counts: 100%|██████████| 702564/702564 [00:00<00:00, 1312757.16it/s]\n",
            "bigram probability:  96%|█████████▌| 15325/15956 [01:06<00:02, 243.12it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(c) Train the model and report its perplexity on the train and validation sets. Is the train or val perplexity higher and why?**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)\n",
        "\n",
        "**(c) What do you notice about the val perplexity and why is this the case?**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "IpU0XsC_7KFo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ntdVf2j24K"
      },
      "source": [
        "#### Add-alpha smoothing\n",
        "Code for sub-part (d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmMeDg-lkQkC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(d) Implement Laplace (add-$\\alpha$) smoothing and retrain the model. Plot the perplexity on train and validation sets as a function of alpha (with values $10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1, 10$).\n",
        "What happens to the validation and training perplexity as we increase alpha and why does this happen?**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)\n",
        "\n",
        "**(d) What seems to be a good setting for alpha? Provide brief justification.**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "NcJF8OBH7x2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(e) Based on your performance in the previous experiments, propose one idea apart from Laplace smoothing to\n",
        "improve the performance of your bigram language model on the validation set. Briefly describe the modification,\n",
        "explain why you expect it will improve validation perplexity, and discuss any potential limitations.**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "SgO4kstsjOlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Prompts\n",
        "\n",
        "If you used an AI tool to complete any part of this assignment, please paste all prompts you used to produce your final code/responses in the box below and answer the following reflection question."
      ],
      "metadata": {
        "id": "wp7yWTZabCoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompts Used:\n",
        "*   \n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "71OQHYMNbVi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection: What parts of the AI generated output required modification or improvement? Describe the feedback you gave the tool to produce your final output or any changes you had to make on your own.**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "KDrwY2DWcTQj"
      }
    }
  ]
}