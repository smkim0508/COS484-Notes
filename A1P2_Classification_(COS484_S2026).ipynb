{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smkim0508/COS484-Notes/blob/main/A1P2_Classification_(COS484_S2026).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VSjS_XAbjQI"
      },
      "source": [
        "# Notebook for Programming Question 2\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing).\n",
        "\n",
        "We'll also be programming in Python, which we will assume a basic familiarity with. Python has fantastic community support and we'll be using numerous packages for machine learning (ML) and natural language processing (NLP) tasks.\n",
        "\n",
        "### Learning Objectives\n",
        "In this problem we will implement logistic regression and test it on a sentiment analysis dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AslCbBsMbol6"
      },
      "source": [
        "### Data Loading and Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOV13zuwihm6"
      },
      "source": [
        "##### You will need to implement a method that processes raw text into feature vectors by mapping vocabulary terms to unique indices. Your implementation needs to support Unigram extraction, where features represent individual word counts, as well as Bigram extraction, where features represent consecutive word pair counts. Make sure your setup correctly handles feature indexing so that the same mapping is applied to both training and development data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlf4P1apdf-w"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaC07CdvlB-9"
      },
      "source": [
        "### Model Implementation\n",
        "\n",
        "You should implement a class that supports the logistic regression logic. This includes:\n",
        "*   **Initialization**: A function to initialize the model parameters (weights and biases) as well as hyperparameters (including the learning rate, regularization parameter, and number of epochs).\n",
        "*   **Optimization**: A training method that iterates through the dataset, calculates the gradient of the loss function for each example or batch, and updates the parameters using your chosen optimization function (we suggest using Stochastic Gradient Descent or Mini-batch SGD for efficiency).\n",
        "*   **Inference**: A function that outputs the model's prediction for a single example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0b4C1DImvuM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cesGHOCipwgL"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "You should implement the logic for your model to train on the given training examples. Experiment with different hyperparameters to find the ones that optimize performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLwZpsU3qC31"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3EqbavuJpz"
      },
      "source": [
        "### Functions for evaluating model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgTqmbGcuM3f"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "manEehMeimHD"
      },
      "source": [
        "### Download and load the training and development data\n",
        "\n",
        "You can download the training and development sets for this problem from the links below:\n",
        "*   Training data: https://princeton-nlp.github.io/cos484/assignments/a1/train.txt\n",
        "*   Development data: https://princeton-nlp.github.io/cos484/assignments/a1/dev.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2cvJYNyjlOy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "m-e2gtKmauos"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kPC-OOmG028Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwrQ1_lHv-Co"
      },
      "source": [
        "### Unigram vs Bigram (No regularization)\n",
        "Code for sub-part (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF2xxlx2roLC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(a) In this part, we want to train the logistic regression model without regularization. Train your model separately with (i) unigram features and (ii) bigram features (two different models). Report both training and development accuracy on the dataset. How do the results of the unigram and bigram models compare?**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "t-cV4JRd8TfH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jnCD2esA5Aa"
      },
      "source": [
        "### Logistic regression with regularization\n",
        "\n",
        "Code for sub-part (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgSNsC5kA9Gs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b) Next, we would like to experiment with $l_2$ regularization $R(\\theta) = \\alpha\\|\\theta\\|^2$. Plot the accuracy on train and development sets as a function of $\\alpha = \\{0, 10^{-2}, 10^{-1}, 1, 10\\}$. You only need to experiment with unigram features for this part. Explain what you observe. Does this match what you would expect from regularization?**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "800iIc0j8c81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(c) Based on your modelâ€™s performance in the previous experiment, propose one change you would consider\n",
        "making to either the model or feature extraction pipeline to further improve development set performance.\n",
        "Briefly describe the modification, explain why you expect it will improve validation perplexity, and discuss any\n",
        "potential limitations.**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "jx7SvZbqkXAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Prompts\n",
        "\n",
        "If you used an AI tool to complete any part of this assignment, please paste all prompts you used to produce your final code/responses in the box below and answer the following reflection question."
      ],
      "metadata": {
        "id": "wp7yWTZabCoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompts Used:\n",
        "*   \n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "HWAVNL5VdZbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection: What parts of the AI generated output required modification or improvement? Describe the feedback you gave the tool to produce your final output or any changes you had to make on your own.**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "KDrwY2DWcTQj"
      }
    }
  ]
}